# Rethinking Foundation Model Adaptation for Dense Regression in Medical Imaging

### [Anonymous MICCAI 2026 Submission #4917]

**TL;DR:** We show that standard foundation model adaptation protocols (freezing layers, shape-preserving losses) degrade performance by 24-27% for dense medical regression. Our gradient-preserving loss achieves 19.04 Œºm MAE, outperforming structured protocols by 27%.

---

## üéØ Quick Start (5 minutes)

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Download Pre-trained Model
```bash
# Our best model (Gradient-Loss, 19.04 Œºm MAE)
wget [ANONYMIZED_LINK]/gradient_loss_best.pth -P checkpoints/
```

### 3. Run Inference on GRAPE
```bash
python scripts/evaluate.py \
    --config configs/gradient_loss.yaml \
    --checkpoint checkpoints/gradient_loss_best.pth \
    --data_path ./data/GRAPE \
    --output results/grape_predictions.csv
```
**Expected output:** MAE ‚âà 19.88 Œºm, œÉ(pred) ‚âà 22.60 Œºm

---

## üìä Main Results (from Paper)

### Table 1: Multi-Backbone Performance and Metric Collapse Analysis
| Backbone | Pre-train | Protocol | MAE ($\mu m$) ‚Üì | Pearson R ‚Üë | Fairness Gap ‚Üì | $\Delta$ vs. Naive ‚Üì | $\sigma_{pred}$ ($\mu m$) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **ImageNet (ViT-B/16)** | Classification | Naive | 19.79 | 0.661 | 1.60 | - | 12.4 |
| | | Aggressive | 19.92 | 0.661 | 1.72 | +0.7% | 12.2 |
| | | Structured | 24.68 | 0.649 | 1.85 | +24.7% | 10.8 |
| **DepthAny (V2-Small)** | Depth (Metric) | Naive | 19.93 | 0.661 | 1.64 | - | 12.5 |
| | | Aggressive | 19.88 | 0.662 | 1.70 | +0.3% | 12.3 |
| | | Structured | 24.75 | 0.645 | 1.82 | +24.2% | 10.6 |
| **RETFound (ViT-L/16)** | MAE Semantic | Naive | 19.52 | 0.662 | 1.68 | - | 12.3 |
| | | Aggressive | 19.25 | 0.676 | 1.79 | -1.4% | 12.3 |
| | | **Gradient-Loss (Ours)** | **19.04\***| **0.676** | 2.40 | **-2.5%** | **11.8** |
| | | Structured | 24.80 | 0.458 | **1.57\***| +27.0% | 4.8 |

<br>

### Table 2: Sector-wise RNFL Regression Results on GRAPE Dataset (Cross-Modality)
| Protocol | Global MAE ‚Üì | Sup. MAE ‚Üì | Nas. MAE ‚Üì | Inf. MAE ‚Üì | Temp. MAE ‚Üë | $\sigma_{pred}$ |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **RETFound (MAE Only)** | 20.12 | 20.45 | 18.90 | 22.34 | 18.79 | 0.82 (Collapsed) |
| **Ours (Grad + MAE)** | **19.88** | **19.61** | **18.56** | **22.12** | **19.25** | **12.15 (Preserved)** |

**Key Finding:** Structured protocols cause "template overfitting" (œÉ=4.8 Œºm), while our gradient loss preserves anatomical diversity (œÉ=11.8 Œºm).

### Table 2: Ablation Study
| Configuration | Frozen (%) | MAE (Œºm) | œÉ(pred) (Œºm) |
| :--- | :--- | :--- | :--- |
| Aggressive | 0% | 19.25 | 12.3 |
| freeze_4 | 17% | 23.07 | 12.0 |
| freeze_8 | 33% | 23.57 | 11.7 |
| freeze_12 | 50% | 24.80 | 11.4 |

**Linear penalty:** $MAE$ = 19.25 + 3.6 x (%frozen/10), $R^2=0.98$

---

## üèóÔ∏è Architecture
```text
Input SLO Image (224√ó224) 
    ‚Üì
RETFound Backbone (ViT-L/16)
    ‚Üì
Projection Head (3-layer MLP ‚Üí 56√ó56 spatial map)
    ‚Üì
Radial Aggregator (360¬∞ circular sampling)
    ‚Üì
RNFL Head (MLP: 360 ‚Üí 512 ‚Üí 360)
    ‚Üì
RNFL Thickness Profile (360 points)
```
**Key Innovation:** Radial Aggregator enforces geometric prior for retinal structure.

---

## üîß Reproducing Paper Results

**Option 1: One-Click Reproduction (Recommended)**
```bash
bash scripts/reproduce_paper.sh
```
This will:
* Train baseline models (Naive, Aggressive, Structured)
* Train our Gradient-Loss model
* Run ablation studies (freezing, loss complexity)
* Generate all tables and figures
* Save results to `results/`
*(Time: ~10 hours on A100 GPU)*

**Option 2: Individual Experiments**
```bash
# Train Gradient-Loss Model
python scripts/train.py \
    --config configs/gradient_loss.yaml \
    --data_path ./data/FairFedMed \
    --output_dir checkpoints/gradient_loss

# Evaluate on Test Set
python scripts/evaluate.py \
    --config configs/gradient_loss.yaml \
    --checkpoint checkpoints/gradient_loss_best.pth \
    --data_path ./data/FairFedMed \
    --split test

# Run Ablation Studies
python scripts/ablation.py \
    --study freezing \
    --data_path ./data/FairFedMed
```

---

## üì¶ Datasets

* **FairFedMed (Primary):** 11,539 images (70/15/15 train/val/test split). Demographics labels included. Format: 224√ó224 fundus images + 360-point RNFL profiles.
* **GRAPE (Cross-Modality Validation):** 243 eyes. Modality: CFP vs SLO. Purpose: Test cross-modality robustness.

**Data Preprocessing:**
```bash
# Download and prepare FairFedMed
python scripts/prepare_fairfedmed.py --download --output data/fairfedmed

# Download and prepare GRAPE
python scripts/prepare_grape.py --download --output data/grape
```

---

## üß™ Key Components

### 1. Radial Aggregator
```python
from models import RadialAggregator
aggregator = RadialAggregator(radius_ratio=0.35, n_points=360)
rnfl_samples = aggregator(spatial_map)  # (B, 56, 56) ‚Üí (B, 360)
```
*Purpose:* Circularly samples spatial features at 30% radius from optic disc center.

### 2. Gradient-Preserving Loss
```python
from losses import GradientLoss
loss_fn = GradientLoss(lambda_gradient=0.2)
loss = loss_fn(predictions, targets)
```
*Formula:* L = \|T_{pred} - T_{gt}\|_1 + \lambda_g \|\nabla T_{pred} - \nabla T_{gt}\|_1
*Effect:* Preserves anatomical transitions while avoiding template overfitting.

### 3. Variance Metrics
```python
import numpy as np
# Compute prediction variance
sigma_pred = np.std(predictions)  # Should be ~11-12 Œºm (healthy)

# Template overfitting check
if sigma_pred < 6:
    print("‚ö†Ô∏è Template overfitting detected!")
```

---

## üìà Expected Results

**On FairFedMed (Test Set)**
* **Gradient-Loss Model:** MAE: 19.04 ¬± 0.06 Œºm | Pearson R: 0.676 | œÉ(pred): 11.8 Œºm | Fairness Gap: 2.40 Œºm

**On GRAPE (Cross-Modality)**
* **Gradient-Loss Model:** MAE: 19.88 Œºm | œÉ(pred): 22.60 Œºm
* **Structured Protocol:** MAE: 34.5 Œºm | œÉ(pred): 4.8 Œºm (collapsed)

---

## üêõ Common Issues
* **CUDA Out of Memory:** Reduce `batch_size` (e.g., to 8 or 4) and increase `gradient_accumulation_steps` in config.
* **Dataset Path Not Found:** Ensure paths in config files use relative paths like `./data/FairFedMed/train` rather than absolute local machine paths.
* **Checkpoint Not Loading:** Run `python scripts/convert_checkpoint.py --input old_checkpoint.pth --output new_checkpoint.pth`

---

## üìä Generating Paper Figures

```bash
# Figure 2: Template Overfitting Visualization
python notebooks/01_visualize_predictions.ipynb

# Tables 1-3: Main Results
python scripts/generate_tables.py --results_dir results/ --output paper_tables.csv
```

---

## üî¨ Ablation Studies
```bash
# Freezing Strategy
python scripts/ablation.py --study freezing

# Loss Complexity
python scripts/ablation.py --study loss_complexity

# Learning Rates
python scripts/ablation.py --study learning_rate
```

---

## üíæ Pre-trained Models
| Model | Config | MAE (Œºm) | Download |
| :--- | :--- | :--- | :--- |
| Gradient-Loss (Best) | `configs/gradient_loss.yaml` | 19.04 | `[ANONYMIZED_LINK]` |
| Aggressive Baseline | `configs/baseline.yaml` | 19.25 | `[ANONYMIZED_LINK]` |
| Structured Protocol | `configs/structured.yaml` | 24.80 | `[ANONYMIZED_LINK]` |





## üìß Contact
For questions or issues regarding this submission, please use the communication portal on the **MICCAI 2026 CMT Platform** to maintain author anonymity.
